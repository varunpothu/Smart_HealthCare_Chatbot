{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "authorship_tag": "ABX9TyOg/W9yoc+JTMfdha2vXS5o",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/varunpothu/Smart_HealthCare_Chatbot/blob/main/QA_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Installing Required Libraries"
      ],
      "metadata": {
        "id": "mcATvQdXJDeR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pandas numpy sentence-transformers streamlit pyngrok\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VCAacxN5JJy9",
        "outputId": "4f7d79ed-241f-4214-c9f2-00cc0d158469"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.10/dist-packages (3.2.1)\n",
            "Requirement already satisfied: streamlit in /usr/local/lib/python3.10/dist-packages (1.40.2)\n",
            "Requirement already satisfied: pyngrok in /usr/local/lib/python3.10/dist-packages (7.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.46.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.66.6)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (2.5.1+cu121)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.5.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.26.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (11.0.0)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.2.2)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.1.7)\n",
            "Requirement already satisfied: packaging<25,>=20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (24.2)\n",
            "Requirement already satisfied: protobuf<6,>=3.20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.25.5)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (17.0.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.32.3)\n",
            "Requirement already satisfied: rich<14,>=10.14.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (13.9.4)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (9.0.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.12.2)\n",
            "Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.10/dist-packages (from streamlit) (6.0.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.10/dist-packages (from streamlit) (3.1.43)\n",
            "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.10/dist-packages (from streamlit) (0.9.1)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (6.3.3)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.10/dist-packages (from pyngrok) (6.0.2)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (3.1.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.12.1)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.11)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.10.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2024.8.30)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (2.18.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.9.11)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.20.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (24.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.21.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mounting the Google Drive"
      ],
      "metadata": {
        "id": "cET5oTyMJQpk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3e_duf5LJV6Y",
        "outputId": "a99e1b38-c7ae-41df-b079-cb5187d2057a"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing the Libraries"
      ],
      "metadata": {
        "id": "AEtsjaOzJYu_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "0WXsuKL3IFzo"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import os\n",
        "\n",
        "import os\n",
        "from threading import Thread\n",
        "from pyngrok import ngrok\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "import shutil\n",
        "\n",
        "from google.colab import files\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Loading"
      ],
      "metadata": {
        "id": "aHhyfpYBJeJS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the Dataset\n",
        "df = pd.read_csv(\"4.csv\")"
      ],
      "metadata": {
        "id": "Y2qFPOBDIO5V"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preprocessing\n"
      ],
      "metadata": {
        "id": "GzPJuoG1Jj9X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Cleaning\n",
        "# Remove duplicates and handle missing values\n",
        "df.drop_duplicates(inplace=True)\n",
        "df.dropna(subset=['question', 'answer'], inplace=True)"
      ],
      "metadata": {
        "id": "iEJrA2KlK_xD"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Text Preprocessing\n",
        "# Removing Special Charectors\n",
        "df['question_clean'] = df['question'].str.lower().str.replace(r'[^\\w\\s]', '', regex=True).str.strip()\n",
        "df['answer_clean'] = df['answer'].str.lower().str.replace(r'[^\\w\\s]', '', regex=True).str.strip()"
      ],
      "metadata": {
        "id": "5rtayFRNOvaV"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Implementation"
      ],
      "metadata": {
        "id": "oRUH4QzxO8dO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Loading\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "# Generate Embeddings\n",
        "df['question_embedding'] = df['question_clean'].apply(lambda x: model.encode(x).tolist())"
      ],
      "metadata": {
        "id": "HNHLVB7IPDUZ"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the cleaned dataset with embeddings\n",
        "output_dataset_path = 'cleaned_dataset_with_embeddings.pkl'\n",
        "with open(output_dataset_path, 'wb') as f:\n",
        "    pickle.dump(df, f)"
      ],
      "metadata": {
        "id": "egU7SsZxpRY0"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inverse Document Metrics (TF-IDF)"
      ],
      "metadata": {
        "id": "Gi3ig9_6q-2C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example documents and query\n",
        "documents = [\"What are the symptoms of glaucoma?\",\n",
        "             \"How is glaucoma treated?\",\n",
        "             \"What causes glaucoma?\"]\n",
        "query = \"What are glaucoma symptoms?\"\n",
        "\n",
        "# Generate TF-IDF vectors\n",
        "vectorizer = TfidfVectorizer()\n",
        "tfidf_matrix = vectorizer.fit_transform(documents)\n",
        "query_vector = vectorizer.transform([query])\n",
        "\n",
        "# Compute cosine similarity\n",
        "similarities = cosine_similarity(query_vector, tfidf_matrix)\n",
        "\n",
        "# Format the similarities to two decimal places\n",
        "formatted_similarities = np.round(similarities, 2)\n",
        "print(formatted_similarities)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yV8sDPgXp-n5",
        "outputId": "c48b23ab-fc0e-4489-8d76-aa1249d161d5"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.77 0.11 0.39]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dot Product"
      ],
      "metadata": {
        "id": "ul8vQ4usrt3I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "documents = [\"What are the symptoms of glaucoma?\",\n",
        "             \"How is glaucoma treated?\",\n",
        "             \"What causes glaucoma?\"]\n",
        "\n",
        "query = \"What are glaucoma symptoms?\"\n",
        "\n",
        "# Generate embeddings\n",
        "doc_embeddings = model.encode(documents)\n",
        "query_embedding = model.encode(query)\n",
        "\n",
        "# Compute dot product similarity\n",
        "similarities = np.dot(doc_embeddings, query_embedding)\n",
        "\n",
        "# Round similarities to two decimal places\n",
        "formatted_similarities = np.round(similarities, 2)\n",
        "print(formatted_similarities)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_-LmIxX_rieC",
        "outputId": "ec1d445a-9744-428a-de9a-74ae98f5c2b8"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.99 0.72 0.78]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Metrics Evaluation\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Function to evaluate metrics (dot product similarity)"
      ],
      "metadata": {
        "id": "viQxM10JsyJ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Retrieval Function\n",
        "def get_answer(query, df, model):\n",
        "    \"\"\"\n",
        "    Retrieve the most relevant answer for the given query.\n",
        "\n",
        "    Parameters:\n",
        "    - query (str): User's question\n",
        "    - df (DataFrame): Preprocessed DataFrame with embeddings\n",
        "    - model (SentenceTransformer): Pretrained embedding model\n",
        "\n",
        "    Returns:\n",
        "    - answer (str): Most relevant answer\n",
        "    - source (str): Source of the answer\n",
        "    - focus_area (str): Topic or focus area of the answer\n",
        "    \"\"\"\n",
        "    # Encode the query\n",
        "    query_embedding = model.encode(query)\n",
        "\n",
        "    # Compute similarity scores\n",
        "    df['similarity'] = df['question_embedding'].apply(lambda x: np.dot(x, query_embedding))\n",
        "\n",
        "    # Get the best match\n",
        "    best_match = df.loc[df['similarity'].idxmax()]\n",
        "    return best_match['answer'], best_match['source'], best_match['focus_area']\n"
      ],
      "metadata": {
        "id": "cCzmHHSbSXku"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testing the bot"
      ],
      "metadata": {
        "id": "ABTApr0atka1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example Usage\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"Healthcare Chatbot Initialized!\")\n",
        "\n",
        "    while True:\n",
        "        # Take user input\n",
        "        user_query = input(\"\\nAsk your healthcare question (type 'exit' to quit): \")\n",
        "        if user_query.lower() == 'exit':\n",
        "            print(\"Goodbye!\")\n",
        "            break\n",
        "\n",
        "        # Get answer\n",
        "        try:\n",
        "            answer, source, focus_area = get_answer(user_query, df, model)\n",
        "            print(f\"\\nAnswer: {answer}\\nSource: {source}\\nFocus Area: {focus_area}\")\n",
        "        except Exception as e:\n",
        "            print(f\"\\nSorry, something went wrong: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vGJbumZwcLLm",
        "outputId": "4153ac62-cdee-49cc-fe84-4330d30e5f57"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Healthcare Chatbot Initialized!\n",
            "\n",
            "Ask your healthcare question (type 'exit' to quit): fever\n",
            "\n",
            "Answer: A fever is a body temperature that is higher than normal. It is not an illness. It is part of your body's defense against infection. Most bacteria and viruses that cause infections do well at the body's normal temperature (98.6 F). A slight fever can make it harder for them to survive. Fever also activates your body's immune system.    Infections cause most fevers. There can be many other causes, including       -  Medicines    -  Heat exhaustion    -  Cancers    -  Autoimmune diseases       Treatment depends on the cause of your fever. Your health care provider may recommend using over-the-counter medicines such as acetaminophen or ibuprofen to lower a very high fever. Adults can also take aspirin, but children with fevers should not take aspirin. It is also important to drink enough liquids to prevent dehydration.\n",
            "Source: MPlusHealthTopics\n",
            "Focus Area: Fever\n",
            "\n",
            "Ask your healthcare question (type 'exit' to quit): cold\n",
            "\n",
            "Answer: Sneezing, sore throat, a stuffy nose, coughing - everyone knows the symptoms of the common cold. It is probably the most common illness. In the course of a year, people in the United States suffer 1 billion colds.    You can get a cold by touching your eyes or nose after you touch surfaces with cold germs on them. You can also inhale the germs. Symptoms usually begin 2 or 3 days after infection and last 2 to 14 days. Washing your hands and staying away from people with colds will help you avoid colds.     There is no cure for the common cold. For relief, try       -  Getting plenty of rest     -  Drinking fluids    -  Gargling with warm salt water     -  Using cough drops or throat sprays    -  Taking over-the-counter pain or cold medicines       However, do not give aspirin to children. And do not give cough medicine to children under four.     NIH: National Institute of Allergy and Infectious Diseases\n",
            "Source: MPlusHealthTopics\n",
            "Focus Area: Common Cold\n",
            "\n",
            "Ask your healthcare question (type 'exit' to quit): exit\n",
            "Goodbye!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Saving the model"
      ],
      "metadata": {
        "id": "C8sFoXj_ta_-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the Model\n",
        "model_save_path = 'sentence_transformer_model'\n",
        "model.save(model_save_path)"
      ],
      "metadata": {
        "id": "EE0AFU6HiXJa"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Compress the model"
      ],
      "metadata": {
        "id": "UhUcY3lAtrBn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compress the model folder into a zip file\n",
        "shutil.make_archive(\"sentence_transformer_model\", 'zip', \"sentence_transformer_model\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "2AyDJlIPtrOH",
        "outputId": "73f79751-d824-4a44-d0ca-c40617bd8285"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/sentence_transformer_model.zip'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download the Zip file"
      ],
      "metadata": {
        "id": "hIxd5-eGt1Wg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the zip file\n",
        "files.download(\"sentence_transformer_model.zip\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "lsxHV_K3txbi",
        "outputId": "94f99cbe-fb38-4fef-c65b-e660c8d8d498"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_0f98a358-1cf8-4164-8c7a-b2dce11da990\", \"sentence_transformer_model.zip\", 83510556)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Temparary Uploading files to Colab"
      ],
      "metadata": {
        "id": "1X2gSfxgt8mX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# uplading the .pkl file and transformer .zip files\n",
        "uploaded = files.upload()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "ysZr0711t8ur",
        "outputId": "e779dc65-75ed-4c6c-9e15-ff3399e4d27a"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-f808d001-ec53-46cf-8e09-1001c6607dc5\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-f808d001-ec53-46cf-8e09-1001c6607dc5\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving cleaned_dataset_with_embeddings.pkl to cleaned_dataset_with_embeddings (1).pkl\n",
            "Saving sentence_transformer_model.zip to sentence_transformer_model (1).zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Accessing the files directly from the Drive"
      ],
      "metadata": {
        "id": "4aoENZHuuiI8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_save_path = '/content/drive/MyDrive/sentence_transformer_model'\n",
        "dataset_path = '/content/drive/MyDrive/cleaned_dataset_with_embeddings.pkl'"
      ],
      "metadata": {
        "id": "Vb1CA1vcugss"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Streamlit Deployment"
      ],
      "metadata": {
        "id": "fcCgYJfcuzrB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Streamlit Front End Code"
      ],
      "metadata": {
        "id": "U4HoBSkhu-Nf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"streamlit_app.py\", \"w\") as f:\n",
        "    f.write(\"\"\"\n",
        "# Streamlit App for Healthcare Chatbot\n",
        "import streamlit as st\n",
        "import pickle\n",
        "import numpy as np\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import re\n",
        "import pandas as pd\n",
        "\n",
        "# Set page configuration (must be the first Streamlit command)\n",
        "st.set_page_config(page_title=\"Smart Healthcare Chatbot\", layout=\"wide\")\n",
        "\n",
        "# Function to clean and preprocess user query\n",
        "def preprocess_query(query):\n",
        "    return re.sub(r'[^\\w\\s]', '', query.lower()).strip()\n",
        "\n",
        "# Load the model and dataset\n",
        "@st.cache_resource\n",
        "def load_model_and_data():\n",
        "    model_path = '/content/drive/My Drive/sentence_transformer_model'\n",
        "    dataset_path = '/content/drive/My Drive/cleaned_dataset_with_embeddings.pkl'\n",
        "    model = SentenceTransformer(model_path)\n",
        "    with open(dataset_path, 'rb') as f:\n",
        "        df = pickle.load(f)\n",
        "    return model, df\n",
        "\n",
        "model, df = load_model_and_data()\n",
        "\n",
        "# Sidebar for additional options\n",
        "st.sidebar.header(\"Navigation\")\n",
        "st.sidebar.markdown(\\\"\"\"\n",
        "- Use the chatbot below to ask healthcare questions.\n",
        "- Browse answers based on focus areas.\n",
        "- Contact support for more help.\n",
        "\\\"\"\")\n",
        "\n",
        "st.sidebar.info(\"**Current Dataset Size:** {} entries\".format(len(df)))\n",
        "\n",
        "# Main application\n",
        "st.title(\"🩺 Smart Healthcare Chatbot\")\n",
        "st.markdown(\\\"\"\"\n",
        "This chatbot helps answer healthcare-related questions. Enter your query below, and the system will provide the most relevant information.\n",
        "\\\"\"\")\n",
        "\n",
        "# User input\n",
        "user_query = st.text_input(\"Ask your healthcare question:\", placeholder=\"Type your question here...\")\n",
        "st.markdown(\"---\")\n",
        "\n",
        "if user_query:\n",
        "    # Process query\n",
        "    query_clean = preprocess_query(user_query)\n",
        "    query_embedding = model.encode(query_clean)\n",
        "\n",
        "    # Calculate similarities and get the top match\n",
        "    df['similarity'] = df['question_embedding'].apply(lambda x: np.dot(query_embedding, x))\n",
        "    top_match = df.loc[df['similarity'].idxmax()]\n",
        "\n",
        "    # Display response with highlighted colors\n",
        "    st.success(f\"### {top_match['answer']}\")\n",
        "    st.markdown(f\"**Source:** <span style='color:blue;'>{top_match['source']}</span>\", unsafe_allow_html=True)\n",
        "    st.markdown(f\"**Focus Area:** <span style='color:green;'>{top_match['focus_area']}</span>\", unsafe_allow_html=True)\n",
        "    st.markdown(f\"### Similarity Score: <span style='color:orange;'>{top_match['similarity']:.2f}</span>\", unsafe_allow_html=True)\n",
        "\n",
        "\n",
        "    # Provide additional recommendations\n",
        "    st.markdown(\"---\")\n",
        "    st.subheader(\"Other Relevant Questions\")\n",
        "    top_similar_questions = df.sort_values(by='similarity', ascending=False).head(3)\n",
        "    for _, row in top_similar_questions.iterrows():\n",
        "        st.write(f\"- **{row['question']}**\")\n",
        "\n",
        "# Footer\n",
        "st.markdown(\"---\")\n",
        "st.info(\"💡 **Tip:** The chatbot is continuously learning. For detailed inquiries, consult a healthcare professional.\")\n",
        "\"\"\")\n"
      ],
      "metadata": {
        "id": "O7aAnikju4NY"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generated Ngrok Authtoken"
      ],
      "metadata": {
        "id": "bWUFqxUNx98I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Authenticate Ngrok\n",
        "!ngrok authtoken 2pPynQ1umOErGUuiyW31IDnmrF1_6VvhjMYosxEu6cnK5g3jx\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fRcMZ_HUvTZD",
        "outputId": "0b180417-1b9e-430e-8843-02b349282c10"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generating Deployment Website"
      ],
      "metadata": {
        "id": "JyLu8W4NyRUO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function to run the Streamlit app\n",
        "def run_streamlit():\n",
        "    os.system(\"streamlit run streamlit_app.py --server.address 0.0.0.0 --server.port 8501\")\n",
        "\n",
        "# Start a thread to run the Streamlit app\n",
        "thread = Thread(target=run_streamlit)\n",
        "thread.start()\n",
        "\n",
        "# Open a tunnel to the Streamlit port (8501) using Ngrok\n",
        "public_url = ngrok.connect(addr=\"8501\", proto=\"http\", bind_tls=True)\n",
        "print('Your Streamlit app is live at:', public_url)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ho_nWcpbvjZc",
        "outputId": "d9fe41bc-968b-4592-b621-ed6c55d8445a"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your Streamlit app is live at: NgrokTunnel: \"https://bf2d-34-44-25-211.ngrok-free.app\" -> \"http://localhost:8501\"\n"
          ]
        }
      ]
    }
  ]
}